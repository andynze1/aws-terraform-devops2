# ðŸŒ AWS Cloud Infrastructure with Terraform, EKS, GitOps, Monitoring & Jenkins

This Terraform project provisions a complete AWS infrastructure stack including:

- ðŸ”§ **Amazon EKS cluster**
- ðŸš€ **GitOps with ArgoCD**
- ðŸ“Š **Monitoring with Prometheus & Grafana**
- âš™ï¸ **Jenkins deployment on EC2**
- ðŸ—‚ï¸ **StorageClasses & DNS**
- ðŸ” **IAM roles & autoscaler**
- ðŸŒ **Route 53 DNS integration**
- ðŸŒ **VPC, subnets, and security groups**
- ðŸ§ª **Sample apps (NGINX, Echo Server)**

---

## ðŸ“¦ Components

### âœ… Core Modules
- `main.tf`, `variables.tf`, `outputs.tf`: Core Terraform infrastructure logic.
- `provider.tf`, `s3-backend.tf`: Cloud provider and backend configuration (S3 + DynamoDB).
- `terraform.tfvars`, `vpc.auto.tfvars`: Parameter values.

### â˜¸ï¸ Kubernetes Cluster
- `eks-cluster.tf`, `eks-securitygroups.tf`, `update-kubeconfig.tf`: Provisions and configures EKS.
- `iam-roles.tf`, `iam-autoscaler.tf`: Creates required IAM roles and bindings.

### ðŸ“Š Monitoring Stack
- `k8s-prometheus.tf`, `k8s-grafana.tf`: Deploys Prometheus & Grafana via Helm.
- `grafana-dashboard.yaml`, `grafana-values.yaml`: Custom dashboards and config.
- `prometheus-stoageclass.yaml`, `storage-class.yaml`: Persistent storage using AWS EBS.

### ðŸš€ GitOps with ArgoCD
- `k8s-argocd.tf`, `argocd.json`: Installs ArgoCD using Helm and sets up the namespace.

### ðŸŒ Networking & DNS
- `namespace.tf`: Defines `monitoring`, `argocd`, and other namespaces.
- `route-53-dns-records.tf`: Creates DNS records in Route 53.
- `aws-data-sources.tf`: Looks up existing VPCs, subnets, and Route 53 zones.

### ðŸ“¡ Sample Applications
- `echoserver.yaml`: A basic echo service with ALB ingress.
- `nginx.yaml`: A multi-replica nginx deployment.
- `crd-grafana.yaml`: (Commented out) Custom Resource Definition for Grafana dashboards.

---

## ðŸ›  Prerequisites

- [Terraform CLI](https://www.terraform.io/downloads)
- [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)
- `kubectl` configured for EKS
- `helm` for Helm chart deployments
- Valid AWS IAM credentials with permission to create infrastructure

---

## â˜¸ï¸ Kubernetes Cluster with EKS

Provisioned using:
- `eks-cluster.tf`
- `eks-securitygroups.tf`
- `update-kubeconfig.tf`

**Features:**
- Managed node groups
- Custom security groups
- IRSA for Kubernetes pods
- `context-k8s.sh` to automatically update kubeconfig

---

## âš™ï¸ Jenkins VM Setup

Jenkins is installed on an EC2 instance provisioned via Terraform and bootstrapped using shell scripts.

### Files:
- `main.tf`, `variables.tf`, `outputs.tf`: Define EC2 instance, security groups, EBS volume, key pairs.
- `install.sh`: Jenkins setup for Ubuntu/Debian-based systems.
- `install-redhat.sh`: Jenkins setup for RHEL-based systems.

### Features:
- Installs Jenkins, Docker, Java, AWS CLI, kubectl, eksctl, helm, Trivy, and Snyk.
- Adds necessary users to the Docker group.

### Access:
- Jenkins UI available via public IP or Route 53 DNS.
- Credentials: admin (set during setup)
- To retrieve Nexus admin password:
  ```bash
  docker exec nexus cat /nexus-data/admin.password

ðŸ“Š Monitoring Stack

Includes:
	â€¢	Prometheus: Cluster metrics and scraping configuration.
	â€¢	Grafana: Dashboards with sidecar-enabled dynamic loading.
	â€¢	Uses:
	â€¢	grafana-values.yaml
	â€¢	grafana-dashboard.yaml
	â€¢	Storage class via prometheus-stoageclass.yaml

Access Grafana via ingress and authenticate with the credentials defined in the values file.

â¸»

ðŸ§ª Sample Applications

Echoserver
	â€¢	K8s service with ALB ingress
	â€¢	Accessible at: echo.devopsbyexample.io

NGINX
	â€¢	4 replica deployment with ClusterIP service

â¸»

ðŸŒ Networking & DNS
	â€¢	VPC, subnets, and route tables defined via network-module.
	â€¢	DNS entries for ArgoCD, Jenkins, and Grafana created in route-53-dns-records.tf.

â¸»

ðŸ“¦ Storage
	â€¢	storage-class.yaml and prometheus-stoageclass.yaml define gp2 storage classes.
	â€¢	Separate classes for monitoring workloads and general use.

â¸»

ðŸ” IAM & Autoscaling
	â€¢	IAM roles defined in:
	â€¢	iam-roles.tf: For EKS nodes and workloads.
	â€¢	iam-autoscaler.tf: Cluster Autoscaler support.

**ðŸš€ Deployment Steps**
1.	Initialize Terraform
    ```bash
    terraform init

2.	Plan the Infrastructure
    ```bash
    terraform plan -out=tfplan

3.	Apply the Plan
    ```bash
    terraform apply tfplan

4.	Configure kubectl
    ```bash
    bash context-k8s.sh

5.	Destroy Infrastructure (if needed)
    ```bash
    terraform destroy

6. Access Jenkins & Grafana
Jenkins: Use EC2 public IP or Route 53
Grafana: Via ALB ingress


ðŸ” Remote State Management

Terraform state is managed remotely using:
	â€¢	S3 bucket for storing state files
	â€¢	DynamoDB for state locking

Configuration: s3-backend.tf

â¸»

ðŸ“¤ Outputs

Post-deployment, the following outputs are available:
	â€¢	EKS cluster name and kubeconfig setup
	â€¢	ArgoCD, Jenkins, and Grafana URLs
	â€¢	IAM role ARNs and resource IDs


**ðŸ“ Directory Structure**
â”œâ”€â”€ modules
    â”œâ”€â”€ eks-module/                        # EKS cluster & node groups
        â”œâ”€â”€ k8s/                        # Kubernetes deployments (ArgoCD, monitoring, storage)
    â”œâ”€â”€ network-module/                    # VPC, subnets, DNS
    â”œâ”€â”€ vm-module/                    # EC2 VM and Jenkins setup
â”œâ”€â”€ main.tf/                    # Bash scripts (kubectl config, Jenkins install)
â”œâ”€â”€ outputs.tf/                 # Example applications (nginx, echoserver)
â”œâ”€â”€ provider.tf
â”œâ”€â”€ README.md
â”œâ”€â”€ s3-backend.tf
â”œâ”€â”€ variables.tf



Terraform VPC and EC2 Module for Workspaces Prod and Stage Environment. With Statefile stored securely in AWS S3. 

ðŸš€ GitOps with ArgoCD
	â€¢	Deployed to argocd namespace.
	â€¢	Accessible via ALB/Ingress configured in k8s-argocd.tf.
	â€¢	Port-forward locally:

To access Nexus Password: docker exec nexus cat /nexus-data/admin.password
nohup kubectl port-forward service/argo-cd-argocd-server -n argocd 8080:443 > argo-portforward.log 2>&1 &

#######

